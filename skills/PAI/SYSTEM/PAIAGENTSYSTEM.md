# PAI Agent System

**Authoritative reference for agent routing in PAI. Three distinct systems existâ€”never confuse them.**

---

## ðŸš¨ THREE AGENT SYSTEMS â€” CRITICAL DISTINCTION

PAI has three agent systems that serve different purposes. Confusing them causes routing failures.

| System | What It Is | When to Use | Has Unique Voice? |
|--------|-----------|-------------|-------------------|
| **Task Tool Subagent Types** | Pre-built agents in Claude Code (Architect, Designer, Engineer, Intern, Explore, etc.) | Internal workflow use ONLY | No |
| **Named Agents** | Persistent identities with backstories and ElevenLabs voices (Serena, Marcus, Rook, etc.) | Recurring work, voice output, relationships | Yes |
| **Custom Agents** | Dynamic agents composed via ComposeAgent from traits | When user says "custom agents" | Yes (trait-mapped) |

---

## ðŸš« FORBIDDEN PATTERNS

**When user says "custom agents":**

```typescript
// âŒ WRONG - These are Task tool subagent_types, NOT custom agents
Task({ subagent_type: "Architect", prompt: "..." })
Task({ subagent_type: "Designer", prompt: "..." })
Task({ subagent_type: "Engineer", prompt: "..." })

// âœ… RIGHT - Invoke the Agents skill for custom agents
Skill("Agents")  // â†’ CreateCustomAgent workflow
// OR follow the workflow directly:
// 1. Run ComposeAgent with different trait combinations
// 2. Launch agents with the generated prompts
// 3. Each gets unique personality + voice
```

---

## Routing Rules

### The Word "Custom" Is the Trigger

| User Says | Action | Implementation |
|-----------|--------|----------------|
| "**custom agents**", "spin up **custom** agents" | Invoke Agents skill | `Skill("Agents")` â†’ CreateCustomAgent workflow |
| "agents", "launch agents", "parallel agents" | Generic Interns | `Task({ subagent_type: "Intern" })` |
| "use Remy", "get Ava to" | Named agent | Use appropriate researcher subagent_type |
| (Internal workflow calls) | Task subagent_types | `Task({ subagent_type: "Engineer" })` etc. |

### Custom Agent Creation Flow

When user requests custom agents:

1. **Invoke Agents skill** via `Skill("Agents")` or follow CreateCustomAgent workflow
2. **Run ComposeAgent** for EACH agent with DIFFERENT trait combinations
3. **Extract prompt and voice_id** from ComposeAgent output
4. **Launch agents** with Task tool using the composed prompts
5. **Voice results** using each agent's unique voice_id

```bash
# Example: 3 custom research agents
bun run ~/.claude/skills/Agents/Tools/ComposeAgent.ts --traits "research,enthusiastic,exploratory"
bun run ~/.claude/skills/Agents/Tools/ComposeAgent.ts --traits "research,skeptical,systematic"
bun run ~/.claude/skills/Agents/Tools/ComposeAgent.ts --traits "research,analytical,synthesizing"
```

---

## Task Tool Subagent Types (Internal Use Only)

These are pre-built agents in the Claude Code Task tool. They are for **internal workflow use**, not for user-requested "custom agents."

| Subagent Type | Purpose | When Used |
|---------------|---------|-----------|
| `Architect` | System design | Development skill workflows |
| `Designer` | UX/UI design | Development skill workflows |
| `Engineer` | Code implementation | Development skill workflows |
| `Intern` | General-purpose parallel work | Parallel grunt work, research |
| `Explore` | Codebase exploration | Finding files, understanding structure |
| `Plan` | Implementation planning | Plan mode |
| `QATester` | Quality assurance | Browser testing workflows |
| `Pentester` | Security testing | WebAssessment workflows |
| `ClaudeResearcher` | Claude-based research | Research skill workflows |
| `GeminiResearcher` | Gemini-based research | Research skill workflows |
| `GrokResearcher` | Grok-based research | Research skill workflows |

**These do NOT have unique voices or ComposeAgent composition.**

---

## Named Agents (Persistent Identities)

Named agents have rich backstories, personality traits, and mapped ElevenLabs voices. They provide relationship continuity across sessions.

| Agent | Role | Voice | Use For |
|-------|------|-------|---------|
| Serena Blackwood | Architect | Premium UK Female | Long-term architecture decisions |
| Marcus Webb | Engineer | Premium Male | Strategic technical leadership |
| Rook Blackburn | Pentester | Enhanced UK Male | Security testing with personality |
| Dev Patel | Intern | High-energy genius | Parallel grunt work |
| Ava Sterling | Claude Researcher | Premium US Female | Strategic research |
| Alex Rivera | Gemini Researcher | Multi-perspective | Comprehensive analysis |

**Full backstories and voice settings:** `skills/Agents/AgentPersonalities.md`

---

## Custom Agents (Dynamic Composition)

Custom agents are composed on-the-fly from traits using ComposeAgent. Each unique trait combination maps to a different ElevenLabs voice.

### Trait Categories

**Expertise** (domain knowledge):
`security`, `legal`, `finance`, `medical`, `technical`, `research`, `creative`, `business`, `data`, `communications`

**Personality** (behavior style):
`skeptical`, `enthusiastic`, `cautious`, `bold`, `analytical`, `creative`, `empathetic`, `contrarian`, `pragmatic`, `meticulous`

**Approach** (work style):
`thorough`, `rapid`, `systematic`, `exploratory`, `comparative`, `synthesizing`, `adversarial`, `consultative`

### Voice Mapping Examples

| Trait Combo | Voice | Why |
|-------------|-------|-----|
| contrarian + skeptical | Clyde (gravelly) | Challenging intensity |
| enthusiastic + creative | Jeremy (energetic) | High-energy creativity |
| security + adversarial | Callum (edgy) | Hacker character |
| analytical + meticulous | Charlotte (sophisticated) | Precision analysis |

**Full trait definitions and voice mappings:** `skills/Agents/Data/Traits.yaml`

---

## Model Selection

Always specify the appropriate model for agent work:

| Task Type | Model | Speed |
|-----------|-------|-------|
| Simple checks, grunt work | `haiku` | 10-20x faster |
| Standard analysis, implementation | `sonnet` | Balanced |
| Deep reasoning, architecture | `opus` | Maximum intelligence |

```typescript
// Parallel custom agents benefit from haiku/sonnet for speed
Task({ prompt: agentPrompt, subagent_type: "Intern", model: "sonnet" })
```

---

## Parallel Dispatch Protocol

### When to Dispatch in Parallel

```
Multiple problems? â”€â”€yesâ”€â”€> Are they independent? â”€â”€yesâ”€â”€> Can agents work without shared state? â”€â”€yesâ”€â”€> PARALLEL DISPATCH
       â”‚                         â”‚                              â”‚
       no                        no (related)                   no (shared state)
       â”‚                         â”‚                              â”‚
  Single agent              Single agent                   Sequential agents
  investigates all          investigates all               (one at a time)
```

**Use parallel dispatch when:**
- 3+ failures across different files/subsystems with different root causes
- Multiple independent tasks with no shared state
- Each problem can be understood without context from the others

**Do NOT use when:**
- Failures are related (fixing one might fix others) â€” investigate together first
- You don't know what's broken yet (exploratory phase)
- Agents would edit the same files or use the same resources
- You need full system understanding before acting

### Agent Prompt Template

Every dispatched agent gets these 4 elements:

```markdown
## SCOPE: [One specific problem domain]
[Exactly what files/tests/subsystem this agent owns]

## GOAL: [One clear outcome]
[What "done" looks like â€” specific and verifiable]

## CONSTRAINTS:
- Do NOT modify files outside [scope]
- Do NOT [specific thing to avoid]
- [Any other boundaries]

## EXPECTED OUTPUT:
Return a summary containing:
1. Root cause identified
2. What you changed and why
3. Verification output (test results, logs, etc.)
4. Whether similar issues exist elsewhere
```

**Example â€” Real dispatch for 3 failing test files:**

```
Agent 1:
  SCOPE: Fix agent-tool-abort.test.ts (3 failures)
  GOAL: All 3 tests pass â€” timing/race condition issues
  CONSTRAINTS: Don't change production code outside abort handling
  OUTPUT: Root cause + fix + passing test output

Agent 2:
  SCOPE: Fix batch-completion-behavior.test.ts (2 failures)
  GOAL: Tools execute correctly in batch mode
  CONSTRAINTS: Don't change abort or race condition code
  OUTPUT: Root cause + fix + passing test output

Agent 3:
  SCOPE: Fix tool-approval-race-conditions.test.ts (1 failure)
  GOAL: Execution count matches expected
  CONSTRAINTS: Don't change batch or abort code
  OUTPUT: Root cause + fix + passing test output
```

### Post-Dispatch Checklist

After all agents return:
1. **Read each summary** â€” Understand what each agent found and changed
2. **Check for conflicts** â€” Did any agents edit the same files?
3. **Run full test suite** â€” All fixes must work together, not just individually
4. **Spot check** â€” Agents can make systematic errors; verify the logic

## Spotcheck Pattern

**Always launch a spotcheck agent after parallel work:**

```typescript
Task({
  prompt: "Verify consistency across all agent outputs: [results]",
  subagent_type: "Intern",
  model: "haiku"
})
```

---

## References

- **Agents Skill:** `skills/Agents/SKILL.md` â€” Custom agent creation, workflows
- **ComposeAgent:** `skills/Agents/Tools/ComposeAgent.ts` â€” Dynamic composition tool
- **Traits:** `skills/Agents/Data/Traits.yaml` â€” Trait definitions and voice mappings
- **Agent Personalities:** `skills/Agents/AgentPersonalities.md` â€” Named agent backstories

---

*Last updated: 2026-01-14*
